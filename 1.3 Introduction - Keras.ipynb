{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section we will use the Kaggle otto challenge.\n",
    "If you want to follow, Get the data from Kaggle: https://www.kaggle.com/c/otto-group-product-classification-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Otto Group is one of the world’s biggest e-commerce companies, A consistent analysis of the performance of products is crucial. However, due to diverse global infrastructure, many identical products get classified differently.\n",
    "For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. \n",
    "Each row corresponds to a single product. There are a total of 93 numerical features, which represent counts of different events. All features have been obfuscated and will not be defined any further.\n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, train=True):\n",
    "    \"\"\"Load data from a CSV File\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        The path to the CSV file\n",
    "        \n",
    "    train: bool (default True)\n",
    "        Decide whether or not data are *training data*.\n",
    "        If True, some random shuffling is applied.\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    X: numpy.ndarray \n",
    "        The data as a multi dimensional array of floats\n",
    "    ids: numpy.ndarray\n",
    "        A vector of ids for each sample\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    if train:\n",
    "        np.random.shuffle(X)  # https://youtu.be/uyUXoap67N8\n",
    "        X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "        return X, labels\n",
    "    else:\n",
    "        X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "        return X, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X, scaler=None):\n",
    "    \"\"\"Preprocess input data by standardise features \n",
    "    by removing the mean and scaling to unit variance\"\"\"\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "\n",
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    \"\"\"Encode labels with values among 0 and `n-classes-1`\"\"\"\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "    return y, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be42e23181e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   0.   0.   0.   3.\n",
      "    2.   1.   0.   0.   0.   0.   0.   0.   0.   5.   3.   1.   1.   0.\n",
      "    0.   0.   0.   0.   1.   0.   0.   1.   0.   1.   0.   1.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   3.   0.   0.   0.   0.   1.   1.\n",
      "    0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  11.   1.  20.   0.   0.   0.   0.   0.]]\n",
      "9 classes\n",
      "93 dims\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "X, labels = load_data('/home/ubuntu/deep-learning-keras-tensorflow/data/train.csv', train=True)\n",
    "X_orig = X.copy()\n",
    "X, scaler = preprocess_data(X)\n",
    "Y, encoder = preprocess_labels(labels)\n",
    "\n",
    "\n",
    "X_test, ids = load_data('/home/ubuntu/deep-learning-keras-tensorflow/data/test.csv', train=False)\n",
    "X_test, ids = X_test[:1000], ids[:1000]\n",
    "\n",
    "#Plotting the data\n",
    "print(X_test[:1])\n",
    "\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "\n",
    "nb_classes = Y.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X.shape[1]\n",
    "print(dims, 'dims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  3.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  5.,  0.],\n",
       "       [ 0.,  0.,  9., ...,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99998945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create and train a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "## Deep Learning library for Theano and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "ref: https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this name, Keras?\n",
    "\n",
    "Keras (κέρας) means _horn_ in Greek. It is a reference to a literary image from ancient Greek and Latin literature, first found in the _Odyssey_, where dream spirits (_Oneiroi_, singular _Oneiros_) are divided between those who deceive men with false visions, who arrive to Earth through a gate of ivory, and those who announce a future that will come to pass, who arrive through a gate of horn. It's a play on the words κέρας (horn) / κραίνω (fulfill), and ἐλέφας (ivory) / ἐλεφαίρομαι (deceive).\n",
    "\n",
    "Keras was initially developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System).\n",
    "\n",
    ">_\"Oneiroi are beyond our unravelling --who can be sure what tale they tell? Not all that men look for comes to pass. Two gates there are that give passage to fleeting Oneiroi; one is made of horn, one of ivory. The Oneiroi that pass through sawn ivory are deceitful, bearing a message that will not be fulfilled; those that come out through polished horn have truth behind them, to be accomplished for men who see them.\"_ Homer, Odyssey 19. 562 ff (Shewring translation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands On - Keras Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 dims\n",
      "Building model...\n",
      "9 classes\n",
      "Epoch 1/1\n",
      "61878/61878 [==============================] - 2s 30us/step - loss: 1.0424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f333766bbe0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = X.shape[1] #number of features in our data  - 93\n",
    "print(dims, 'dims')\n",
    "print(\"Building model...\")\n",
    "\n",
    "nb_classes = Y.shape[1] #number of classes in our data - 9\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "model = Sequential() #intialize a model\n",
    "model.add(Dense(nb_classes, input_shape=(dims,))) #add a fully connected layer with 9 neurons\n",
    "model.add(Activation('softmax')) #add softmax activation\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy') #add the sgd optimizer to optimize our model \n",
    "model.fit(X, Y) #start optimizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy is 0.7260738873266751\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy is {0}'.format(sum(Y.argmax(axis=1)==train_predictions)/train_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplicity is pretty impressive right? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets understand:\n",
    "<pre>The core data structure of Keras is a <b>model</b>, a way to organize layers. The main type of model is the <b>Sequential</b> model, a linear stack of layers.</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did here is stacking a Fully Connected (<b>Dense</b>) layer of trainable weights from the input to the output and an <b>Activation</b> layer on top of the weights layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "Dense(output_dim, init='glorot_uniform', activation='linear', \n",
    "      weights=None, W_regularizer=None, b_regularizer=None,\n",
    "      activity_regularizer=None, W_constraint=None, \n",
    "      b_constraint=None, bias=True, input_dim=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "from keras.layers.core import Activation\n",
    "\n",
    "Activation(activation)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code).\n",
    "Here we used <b>SGD</b> (stochastic gradient descent) as an optimization algorithm for our trainable weights.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Data Sciencing\" this example a little bit more\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did here is nice, however in the real world it is not useable because of overfitting.\n",
    "Lets try and solve it with cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In overfitting, a statistical model describes random error or noise instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. \n",
    "\n",
    "A model that has been overfit has poor predictive performance, as it overreacts to minor fluctuations in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src =\"imgs/overfitting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>To avoid overfitting, we will first split out data to training set and test set and test out model on the test set.\n",
    "Next: we will use two of keras's callbacks <b>EarlyStopping</b> and <b>ModelCheckpoint</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/20\n",
      "13824/52596 [======>.......................] - ETA: 0s - loss: 0.8194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.8019 - val_loss: 0.7711\n",
      "Epoch 2/20\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 0.7834 - val_loss: 0.7549\n",
      "Epoch 3/20\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 0.7691 - val_loss: 0.7421\n",
      "Epoch 4/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.7577 - val_loss: 0.7316\n",
      "Epoch 5/20\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 0.7484 - val_loss: 0.7226\n",
      "Epoch 6/20\n",
      "52596/52596 [==============================] - 1s 12us/step - loss: 0.7405 - val_loss: 0.7152\n",
      "Epoch 7/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7338 - val_loss: 0.7086\n",
      "Epoch 8/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7279 - val_loss: 0.7027\n",
      "Epoch 9/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7229 - val_loss: 0.6980\n",
      "Epoch 10/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7183 - val_loss: 0.6936\n",
      "Epoch 11/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7143 - val_loss: 0.6895\n",
      "Epoch 12/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7106 - val_loss: 0.6860\n",
      "Epoch 13/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7073 - val_loss: 0.6831\n",
      "Epoch 14/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7044 - val_loss: 0.6800\n",
      "Epoch 15/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.7016 - val_loss: 0.6774\n",
      "Epoch 16/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.6991 - val_loss: 0.6746\n",
      "Epoch 17/20\n",
      "52596/52596 [==============================] - 1s 10us/step - loss: 0.6967 - val_loss: 0.6724\n",
      "Epoch 18/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.6946 - val_loss: 0.6704\n",
      "Epoch 19/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.6925 - val_loss: 0.6684\n",
      "Epoch 20/20\n",
      "52596/52596 [==============================] - 1s 11us/step - loss: 0.6906 - val_loss: 0.6669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f33376880f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "fBestModel = 'best_model.h5' \n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=1) \n",
    "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), nb_epoch=20, \n",
    "          batch_size=128, verbose=True, validation_split=0.15, \n",
    "          callbacks=[best_model, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy is 0.7491444216290212\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train).argmax(axis=1)\n",
    "print('train accuracy is {0}'.format(sum(Y_train.argmax(axis=1)==train_predictions)/train_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is 0.7557638439991381\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_val).argmax(axis=1)\n",
    "print('test accuracy is {0}'.format(sum(Y_val.argmax(axis=1)==val_predictions)/val_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron and Fully Connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how hard can it be to build a Multi-Layer percepton with keras?\n",
    "It is baiscly the same, just add more layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/20\n",
      "52596/52596 [==============================] - 1s 19us/step - loss: 1.1997 - val_loss: 0.8781\n",
      "Epoch 2/20\n",
      "52596/52596 [==============================] - 1s 16us/step - loss: 0.8304 - val_loss: 0.7738\n",
      "Epoch 3/20\n",
      "52596/52596 [==============================] - 1s 19us/step - loss: 0.7672 - val_loss: 0.7297\n",
      "Epoch 4/20\n",
      "52596/52596 [==============================] - 1s 15us/step - loss: 0.7354 - val_loss: 0.7046\n",
      "Epoch 5/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.7160 - val_loss: 0.6879\n",
      "Epoch 6/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.7028 - val_loss: 0.6755\n",
      "Epoch 7/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6933 - val_loss: 0.6673\n",
      "Epoch 8/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6859 - val_loss: 0.6602\n",
      "Epoch 9/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6802 - val_loss: 0.6555\n",
      "Epoch 10/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6757 - val_loss: 0.6517\n",
      "Epoch 11/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6719 - val_loss: 0.6474\n",
      "Epoch 12/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6687 - val_loss: 0.6447\n",
      "Epoch 13/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6658 - val_loss: 0.6418\n",
      "Epoch 14/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6634 - val_loss: 0.6397\n",
      "Epoch 15/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6613 - val_loss: 0.6376\n",
      "Epoch 16/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6593 - val_loss: 0.6367\n",
      "Epoch 17/20\n",
      "52596/52596 [==============================] - 1s 13us/step - loss: 0.6576 - val_loss: 0.6341\n",
      "Epoch 18/20\n",
      "52596/52596 [==============================] - 1s 15us/step - loss: 0.6561 - val_loss: 0.6336\n",
      "Epoch 19/20\n",
      "52596/52596 [==============================] - 1s 14us/step - loss: 0.6547 - val_loss: 0.6320\n",
      "Epoch 20/20\n",
      "52596/52596 [==============================] - 1s 15us/step - loss: 0.6535 - val_loss: 0.6305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f332a69f208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(dims,)))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), nb_epoch=20, \n",
    "          batch_size=128, verbose=True, validation_split=0.15, \n",
    "          callbacks=[best_model, early_stop]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy is 0.7587649250893604\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train).argmax(axis=1)\n",
    "print('train accuracy is {0}'.format(sum(Y_train.argmax(axis=1)==train_predictions)/train_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is 0.7670760611937083\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_val).argmax(axis=1)\n",
    "print('test accuracy is {0}'.format(sum(Y_val.argmax(axis=1)==val_predictions)/val_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands On - Keras Fully Connected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take couple of minutes and Try and optimize the number of layers and the number of parameters in the layers to get the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/50\n",
      "52596/52596 [==============================] - 6s 108us/step - loss: 0.8818 - val_loss: 0.7093\n",
      "Epoch 2/50\n",
      "52596/52596 [==============================] - 5s 97us/step - loss: 0.7131 - val_loss: 0.6717\n",
      "Epoch 3/50\n",
      "52596/52596 [==============================] - 5s 102us/step - loss: 0.6871 - val_loss: 0.6597\n",
      "Epoch 4/50\n",
      "52596/52596 [==============================] - 6s 105us/step - loss: 0.6753 - val_loss: 0.6488\n",
      "Epoch 5/50\n",
      "52596/52596 [==============================] - 5s 87us/step - loss: 0.6669 - val_loss: 0.6400\n",
      "Epoch 6/50\n",
      "52596/52596 [==============================] - 5s 97us/step - loss: 0.6634 - val_loss: 0.6355\n",
      "Epoch 7/50\n",
      "52596/52596 [==============================] - 5s 87us/step - loss: 0.6596 - val_loss: 0.6359\n",
      "Epoch 8/50\n",
      "52596/52596 [==============================] - 6s 106us/step - loss: 0.6567 - val_loss: 0.6336\n",
      "Epoch 9/50\n",
      "52596/52596 [==============================] - 5s 99us/step - loss: 0.6561 - val_loss: 0.6367\n",
      "Epoch 10/50\n",
      "52596/52596 [==============================] - 5s 104us/step - loss: 0.6536 - val_loss: 0.6275\n",
      "Epoch 11/50\n",
      "52596/52596 [==============================] - 5s 103us/step - loss: 0.6519 - val_loss: 0.6287\n",
      "Epoch 12/50\n",
      "52596/52596 [==============================] - 5s 101us/step - loss: 0.6509 - val_loss: 0.6252\n",
      "Epoch 13/50\n",
      "52596/52596 [==============================] - 5s 102us/step - loss: 0.6493 - val_loss: 0.6305\n",
      "Epoch 14/50\n",
      "52596/52596 [==============================] - 7s 125us/step - loss: 0.6485 - val_loss: 0.6249\n",
      "Epoch 15/50\n",
      "52596/52596 [==============================] - 5s 101us/step - loss: 0.6474 - val_loss: 0.6261\n",
      "Epoch 16/50\n",
      "52596/52596 [==============================] - 6s 109us/step - loss: 0.6475 - val_loss: 0.6320\n",
      "Epoch 17/50\n",
      "52596/52596 [==============================] - 6s 119us/step - loss: 0.6468 - val_loss: 0.6234\n",
      "Epoch 18/50\n",
      "52596/52596 [==============================] - 6s 110us/step - loss: 0.6460 - val_loss: 0.6251\n",
      "Epoch 19/50\n",
      "52596/52596 [==============================] - 5s 103us/step - loss: 0.6459 - val_loss: 0.6196\n",
      "Epoch 20/50\n",
      "52596/52596 [==============================] - 5s 95us/step - loss: 0.6448 - val_loss: 0.6222\n",
      "Epoch 21/50\n",
      "52596/52596 [==============================] - 5s 102us/step - loss: 0.6450 - val_loss: 0.6238\n",
      "Epoch 22/50\n",
      "52596/52596 [==============================] - 6s 105us/step - loss: 0.6433 - val_loss: 0.6241\n",
      "Epoch 23/50\n",
      "52596/52596 [==============================] - 5s 97us/step - loss: 0.6442 - val_loss: 0.6225\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f332a2f1c88>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(dims,)))\n",
    "# Play with it! add as much layers as you want! try and get better results.\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(nb_classes))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), nb_epoch=50, \n",
    "          batch_size=128, verbose=True, validation_split=0.15, \n",
    "          callbacks=[best_model, early_stop]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy is 0.7642134522770613\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model.predict(X).argmax(axis=1)\n",
    "print('train accuracy is {0}'.format(sum(Y.argmax(axis=1)==train_predictions)/train_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is 0.7693385046326223\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(X_val).argmax(axis=1)\n",
    "print('test accuracy is {0}'.format(sum(Y_val.argmax(axis=1)==val_predictions)/val_predictions.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's overfit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/deep-learning/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 1/30\n",
      "52596/52596 [==============================] - 15s 287us/step - loss: 0.7898 - val_loss: 0.6634\n",
      "Epoch 2/30\n",
      "52596/52596 [==============================] - 15s 286us/step - loss: 0.6838 - val_loss: 0.6432\n",
      "Epoch 3/30\n",
      "52596/52596 [==============================] - 15s 283us/step - loss: 0.6698 - val_loss: 0.6380\n",
      "Epoch 4/30\n",
      "52596/52596 [==============================] - 15s 285us/step - loss: 0.6650 - val_loss: 0.6396\n",
      "Epoch 5/30\n",
      "52596/52596 [==============================] - 15s 290us/step - loss: 0.6611 - val_loss: 0.6320\n",
      "Epoch 6/30\n",
      "52596/52596 [==============================] - 16s 295us/step - loss: 0.6584 - val_loss: 0.6292\n",
      "Epoch 7/30\n",
      "52596/52596 [==============================] - 15s 285us/step - loss: 0.6567 - val_loss: 0.6305\n",
      "Epoch 8/30\n",
      "52596/52596 [==============================] - 16s 295us/step - loss: 0.6551 - val_loss: 0.6276\n",
      "Epoch 9/30\n",
      "52596/52596 [==============================] - 16s 311us/step - loss: 0.6535 - val_loss: 0.6267\n",
      "Epoch 10/30\n",
      "52596/52596 [==============================] - 18s 345us/step - loss: 0.6525 - val_loss: 0.6335\n",
      "Epoch 11/30\n",
      "52596/52596 [==============================] - 15s 294us/step - loss: 0.6520 - val_loss: 0.6233\n",
      "Epoch 12/30\n",
      "52596/52596 [==============================] - 17s 320us/step - loss: 0.6504 - val_loss: 0.6248\n",
      "Epoch 13/30\n",
      "52596/52596 [==============================] - 15s 286us/step - loss: 0.6491 - val_loss: 0.6301\n",
      "Epoch 14/30\n",
      "52596/52596 [==============================] - 15s 288us/step - loss: 0.6482 - val_loss: 0.6214\n",
      "Epoch 15/30\n",
      "52596/52596 [==============================] - 18s 349us/step - loss: 0.6485 - val_loss: 0.6198\n",
      "Epoch 16/30\n",
      "52596/52596 [==============================] - 18s 335us/step - loss: 0.6467 - val_loss: 0.6231\n",
      "Epoch 17/30\n",
      "52596/52596 [==============================] - 15s 291us/step - loss: 0.6465 - val_loss: 0.6214\n",
      "Epoch 18/30\n",
      "52596/52596 [==============================] - 15s 291us/step - loss: 0.6458 - val_loss: 0.6219\n",
      "Epoch 19/30\n",
      "52596/52596 [==============================] - 17s 314us/step - loss: 0.6464 - val_loss: 0.6216\n",
      "Epoch 20/30\n",
      "52596/52596 [==============================] - 15s 290us/step - loss: 0.6451 - val_loss: 0.6221\n",
      "Epoch 21/30\n",
      "52596/52596 [==============================] - 15s 292us/step - loss: 0.6452 - val_loss: 0.6222\n",
      "Epoch 22/30\n",
      "52596/52596 [==============================] - 20s 388us/step - loss: 0.6448 - val_loss: 0.6239\n",
      "Epoch 23/30\n",
      "52596/52596 [==============================] - 18s 338us/step - loss: 0.6444 - val_loss: 0.6194\n",
      "Epoch 24/30\n",
      "52596/52596 [==============================] - 15s 290us/step - loss: 0.6441 - val_loss: 0.6189\n",
      "Epoch 25/30\n",
      "52596/52596 [==============================] - 18s 334us/step - loss: 0.6443 - val_loss: 0.6170\n",
      "Epoch 26/30\n",
      "52596/52596 [==============================] - 16s 298us/step - loss: 0.6439 - val_loss: 0.6202\n",
      "Epoch 27/30\n",
      "52596/52596 [==============================] - 16s 296us/step - loss: 0.6427 - val_loss: 0.6186\n",
      "Epoch 28/30\n",
      "52596/52596 [==============================] - 18s 345us/step - loss: 0.6431 - val_loss: 0.6206\n",
      "Epoch 29/30\n",
      "52596/52596 [==============================] - 16s 308us/step - loss: 0.6429 - val_loss: 0.6186\n",
      "Epoch 30/30\n",
      "52596/52596 [==============================] - 19s 364us/step - loss: 0.6429 - val_loss: 0.6217\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(dims,)))\n",
    "# Play with it! add as much layers as you want! try and get better results.\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(nb_classes))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), nb_epoch=30, \n",
    "          batch_size=128, verbose=True, validation_split=0.15, ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3329c16780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJRUWCIiEhUFBgiIhKV/w8cYAu9n4DgIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f332a368588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a question answering system, an image classification model, a Neural Turing Machine, a word2vec embedder or any other model is just as fast. The ideas behind deep learning are simple, so why should their implementation be painful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical Motivations for depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Much has been studied about the depth of neural nets. Is has been proven mathematically[1] and empirically that convolutional neural network benifit from depth! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] - On the Expressive Power of Deep Learning: A Tensor Analysis - Cohen, et al 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theoretical Motivations for depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One much quoted theorem about neural network states that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Universal approximation theorem states[1] that a feed-forward network with a single hidden layer containing a finite number of neurons (i.e., a multilayer perceptron), can approximate continuous functions on compact subsets of $\\mathbb{R}^n$, under mild assumptions on the activation function. The theorem thus states that simple neural networks can represent a wide variety of interesting functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] - Approximation Capabilities of Multilayer Feedforward Networks - Kurt Hornik 1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
